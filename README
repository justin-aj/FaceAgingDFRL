 
FOLDERS in DATA:

1. cropped UTKFace - all the cropped 512 * 512 images of UTK face (cant upload this to git as its huge)
2. csv- all csv files needed for the project.
3. Subset 150- final high qality 150 images for pre-training.
4. UTKface- original UTKface images(cant upload this to git as its huge)


DATA PREPROCESING: 

1. Crop all images and discard blurry ones from UTkFaces.

2. Create 150 subset of high-quality images for pretraining(In Section 4: Experiments, they say: 150 training images are sampled from FFHQ-Aging...
We used the central age of the true label age group as Î± in the finetuning prompt.). Not using more images due to resource constraints!!

Example Target Age Groups used for our project for finetuning pre-trained model
0â€“9 â†’ "0s"

10â€“19 â†’ "10s"

...

70+ â†’ "70s"

#final subset of 150 images:

Race	Age Groups Covered	Sample Count
Black	0s, 10s, ..., 70s+	up to 35
White	0s, 10s, ..., 70s+	up to 35
Asian	0s, 10s, ..., 70s+	up to 35
Indian	0s, 10s, ..., 70s+	up to 35
Other	0s, 10s, ..., 70s+	up to 35

3. Generating age conditioned prompts in csv(done in FADING research paper)- but we can try more with race if we have time


4. Load image data and tensors into PromptDataset


IMPLEMENTING:

1. Load Pretrained Stable Diffusion
Use diffusers from Hugging Face to load:

    StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4")

Extract and fine-tune only the UNet (just like in the FADING paper)


2. Fine-Tuning (Double Prompt Scheme)
For each image:

Use two prompts:

P_Î± = "a photo of a 42 year old person" â†’ age prompt

P = "a photo of a person" â†’ neutral prompt

      Optimize for: L = ||SD(PÎ±) - GT|| - ||SD(P) - GT||

â†’ This helps the model learn aging features while preserving identity


3. Save The Fine-Tuned Model
Save only the UNet weights (you donâ€™t need to retrain the text encoder or VAE)

This becomes the new specialized FADING model.


4.  Inference & Age Editing
Use null-text inversion to embed a face into latent space

Use prompt editing to apply age changes:
Original prompt: "a photo of a 40 year old person"
Edited prompt:   "a photo of a 70 year old person"
Generate aged images


Testing project results: What can be the quatifiable results in the project-??

1. Using a pretrained age determination model-??
2. What else-?


ðŸ“Š Quantitative Evaluation Metrics
As detailed in Section 4 of the paper, the authors evaluated their aging results using the following metrics:

1. Mean Absolute Error (MAE)
Measures the difference between the predicted age (via Face++ age estimator- no , insight face -yes) and the target prompt age.

Lower MAE = better alignment between prompt and generated face.

2. Gender, Smile, and Facial Expression Preservation
Attribute preservation scores are computed using Face++ API.

Reported as the percentage of original attributes retained after aging.

3. Blurriness
Measures face clarity, again evaluated using Face++.

Lower values indicate sharper, higher-quality faces.

4. Kernel Inception Distance (KID)
Evaluates visual realism by comparing distributions of generated and real face images (within the same age group).

Lower KID = better image quality and realismâ€‹


File contents:

1. addPromptColumnfor150imagescsv.py   generates the correct prompt for all the 150 cropped UTK images in the subset150 folder and adds the prompt to the corresponding image data entry in the train_balanced_with_prompts.csv file.

2. ageEstimator.py file contains code to determine the age of the person in an image. Can be used for testing the results of our project. Uses insightface for age estimtion.

3. cropFaces.py  files contains code for preprocessing(crops the images which have some good resolution, skips the rest) the imges from src_dir = "data/UTKFace"
to dst_dir = "data/croppedUTKFace".

4. prompt_dataset.py cotains the class to store the image information as tensor data. Can be used by the model if needed.

5. subset150.py contains the logic to create a subset of 150 images data into utk_train_balanced.csv from the croppedUTKface images folder for pretaining(step 2 mentioned in preprocessing info)

6. test150.py has tests to see the 150 images generated by subset.py are of good clarity, and as per logic specified to ensure enthnical diversity and age diversity.

7. testCropping.py tests to check cropFaces.py

8. testDataLoader.py test to check if prompt_dataset.py is working.

9. evaluateFolder.py Contains helper methods for evaluateModel.py

10. evaluateModel.py run this folder to run evaluation for the outputs generated by model. 





 
