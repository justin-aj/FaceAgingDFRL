{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c161a5d2-34a7-428d-97b4-f23e12ee10f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import shutil\n",
    "\n",
    "from diffusers import (\n",
    "    StableDiffusionPipeline, \n",
    "    DPMSolverMultistepScheduler,\n",
    "    StableDiffusionImg2ImgPipeline\n",
    ")\n",
    "\n",
    "# Define constants\n",
    "DEFAULT_BASE_MODEL = \"runwayml/stable-diffusion-v1-5\"\n",
    "DEFAULT_OUTPUT_DIR = \"./face_aging_model\"\n",
    "DEFAULT_DATASET_DIR = \"./datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b784e18f-1ce7-4131-b00c-11cc2c4563ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, output_path=None):\n",
    "    \"\"\"Download an image from a URL\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            if output_path:\n",
    "                with open(output_path, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "                return output_path\n",
    "            else:\n",
    "                return Image.open(BytesIO(response.content))\n",
    "        else:\n",
    "            print(f\"Failed to download image: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image: {e}\")\n",
    "        return None\n",
    "\n",
    "def download_sample_images(output_dir=DEFAULT_DATASET_DIR):\n",
    "    \"\"\"Download sample images for different age groups\"\"\"\n",
    "    print(\"Downloading sample images...\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define age groups and sample image URLs (using FFHQ dataset samples)\n",
    "    age_groups = {\n",
    "        \"child\": [\n",
    "            \"https://raw.githubusercontent.com/NVlabs/ffhq-dataset/master/thumbnails128x128/00000/00000.png\",\n",
    "            \"https://raw.githubusercontent.com/NVlabs/ffhq-dataset/master/thumbnails128x128/00001/00001.png\",\n",
    "        ],\n",
    "        \"young_adult\": [\n",
    "            \"https://raw.githubusercontent.com/NVlabs/ffhq-dataset/master/thumbnails128x128/00002/00002.png\",\n",
    "            \"https://raw.githubusercontent.com/NVlabs/ffhq-dataset/master/thumbnails128x128/00003/00003.png\",\n",
    "        ],\n",
    "        \"middle_aged\": [\n",
    "            \"https://raw.githubusercontent.com/NVlabs/ffhq-dataset/master/thumbnails128x128/00004/00004.png\",\n",
    "            \"https://raw.githubusercontent.com/NVlabs/ffhq-dataset/master/thumbnails128x128/00005/00005.png\",\n",
    "        ],\n",
    "        \"elderly\": [\n",
    "            \"https://raw.githubusercontent.com/NVlabs/ffhq-dataset/master/thumbnails128x128/00006/00006.png\",\n",
    "            \"https://raw.githubusercontent.com/NVlabs/ffhq-dataset/master/thumbnails128x128/00007/00007.png\",\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Download images for each age group\n",
    "    for age_group, urls in age_groups.items():\n",
    "        group_dir = os.path.join(output_dir, age_group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "        \n",
    "        for i, url in enumerate(urls):\n",
    "            try:\n",
    "                response = requests.get(url, timeout=10)\n",
    "                if response.status_code == 200:\n",
    "                    img = Image.open(BytesIO(response.content))\n",
    "                    img_path = os.path.join(group_dir, f\"{i}.png\")\n",
    "                    img.save(img_path)\n",
    "                    \n",
    "                    # Create a caption file for the image\n",
    "                    caption_path = os.path.join(group_dir, f\"{i}.txt\")\n",
    "                    with open(caption_path, 'w') as f:\n",
    "                        age = 5 if age_group == \"child\" else \\\n",
    "                              25 if age_group == \"young_adult\" else \\\n",
    "                              45 if age_group == \"middle_aged\" else 75\n",
    "                        f.write(f\"a detailed photograph of a {age_group} person, {age} years old\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading {url}: {e}\")\n",
    "    \n",
    "    print(f\"Sample images created at {output_dir}\")\n",
    "    return output_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc3de4b-5cd5-4b89-aa74-f80b5779be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_face(\n",
    "    image_path,\n",
    "    base_model_path=DEFAULT_BASE_MODEL,\n",
    "    target_age=\"elderly\",\n",
    "    target_age_value=75,\n",
    "    strength=0.75,\n",
    "    num_inference_steps=30,\n",
    "    guidance_scale=7.5,\n",
    "    output_path=None\n",
    "):\n",
    "    \"\"\"Apply age transformation to a face image using text-to-image prompting\"\"\"\n",
    "    # Load models\n",
    "    print(f\"Loading model {base_model_path}...\")\n",
    "    \n",
    "    # Choose pipeline based on whether we want to use an existing image\n",
    "    if os.path.exists(image_path) or image_path.startswith(\"http\"):\n",
    "        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "            base_model_path,\n",
    "            torch_dtype=torch.float16,\n",
    "            safety_checker=None\n",
    "        ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        img2img = True\n",
    "    else:\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            base_model_path,\n",
    "            torch_dtype=torch.float16,\n",
    "            safety_checker=None\n",
    "        ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        img2img = False\n",
    "    \n",
    "    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "    \n",
    "    # Load input image if we're doing img2img\n",
    "    if img2img:\n",
    "        if isinstance(image_path, str):\n",
    "            if image_path.startswith(\"http\"):\n",
    "                init_image = download_image(image_path)\n",
    "            else:\n",
    "                init_image = Image.open(image_path).convert(\"RGB\")\n",
    "        else:\n",
    "            # Assume it's already a PIL image\n",
    "            init_image = image_path\n",
    "        \n",
    "        # Resize image\n",
    "        width, height = init_image.size\n",
    "        if width > 768 or height > 768:\n",
    "            # Maintain aspect ratio\n",
    "            if width > height:\n",
    "                new_width = 768\n",
    "                new_height = int(height * (768 / width))\n",
    "            else:\n",
    "                new_height = 768\n",
    "                new_width = int(width * (768 / height))\n",
    "            init_image = init_image.resize((new_width, new_height), Image.LANCZOS)\n",
    "    \n",
    "    # Create prompt for different ages\n",
    "    age_descriptions = {\n",
    "        \"child\": \"a young child, about 5-8 years old\",\n",
    "        \"teen\": \"a teenager, about 15-18 years old\",\n",
    "        \"young_adult\": \"a young adult, about 25-30 years old\",\n",
    "        \"middle_aged\": \"a middle-aged person, about 45-50 years old\",\n",
    "        \"elderly\": \"an elderly person, about 70-80 years old\",\n",
    "    }\n",
    "    \n",
    "    # Get description or use target_age as is if not found\n",
    "    age_desc = age_descriptions.get(target_age, f\"a {target_age} person, {target_age_value} years old\")\n",
    "    \n",
    "    # Craft prompt\n",
    "    prompt = f\"a highly detailed realistic photograph of {age_desc}, same person, same identity, detailed face, high quality, detailed skin\"\n",
    "    \n",
    "    # Add age-specific details\n",
    "    if \"elderly\" in target_age or target_age_value >= 65:\n",
    "        prompt += \", wrinkles, gray hair, aged skin\"\n",
    "    elif \"middle\" in target_age or 40 <= target_age_value < 65:\n",
    "        prompt += \", slight wrinkles, mature face\"\n",
    "    elif \"young\" in target_age or 20 <= target_age_value < 40:\n",
    "        prompt += \", youthful appearance\"\n",
    "    elif \"teen\" in target_age or 13 <= target_age_value < 20:\n",
    "        prompt += \", teenage appearance, young face\"\n",
    "    elif \"child\" in target_age or target_age_value < 13:\n",
    "        prompt += \", childlike features, young face, smooth skin\"\n",
    "    \n",
    "    # Negative prompt to avoid distortion\n",
    "    negative_prompt = \"deformed, distorted, disfigured, poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs, mutation, mutated, ugly, disgusting, blurry\"\n",
    "    \n",
    "    print(f\"Generating {target_age} version with prompt: {prompt}\")\n",
    "    \n",
    "    # Generate image\n",
    "    if img2img:\n",
    "        result = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            image=init_image,\n",
    "            strength=strength,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale\n",
    "        )\n",
    "    else:\n",
    "        result = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale\n",
    "        )\n",
    "    \n",
    "    aged_image = result.images[0]\n",
    "    \n",
    "    # Save output if specified\n",
    "    if output_path:\n",
    "        os.makedirs(os.path.dirname(os.path.abspath(output_path)), exist_ok=True)\n",
    "        aged_image.save(output_path)\n",
    "        print(f\"Aged image saved to {output_path}\")\n",
    "    \n",
    "    # Display the image in the notebook\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(np.array(aged_image))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{target_age} ({target_age_value} years)\")\n",
    "    plt.show()\n",
    "    \n",
    "    return aged_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90423fa4-023b-49ca-be7f-1d110f6d0df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_age_progression(\n",
    "    image_path,\n",
    "    base_model_path=DEFAULT_BASE_MODEL,\n",
    "    output_dir=\"./age_progressions\",\n",
    "    age_steps=[(\"child\", 7), (\"young_adult\", 25), (\"middle_aged\", 45), (\"elderly\", 75)],\n",
    "    strength=0.75,\n",
    "    guidance_scale=7.5\n",
    "):\n",
    "    \"\"\"Generate a series of age progressions for a face\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create a subplot for all ages\n",
    "    fig, axes = plt.subplots(1, len(age_steps) + 1, figsize=(4 * (len(age_steps) + 1), 4))\n",
    "    \n",
    "    # Load and display original image\n",
    "    if isinstance(image_path, str):\n",
    "        if image_path.startswith(\"http\"):\n",
    "            original_image = download_image(image_path)\n",
    "        else:\n",
    "            original_image = Image.open(image_path).convert(\"RGB\")\n",
    "    else:\n",
    "        original_image = image_path\n",
    "    \n",
    "    # Display original image\n",
    "    axes[0].imshow(np.array(original_image))\n",
    "    axes[0].set_title(\"Original\")\n",
    "    axes[0].axis(\"off\")\n",
    "    \n",
    "    # Save original image\n",
    "    original_path = os.path.join(output_dir, \"original.png\")\n",
    "    original_image.save(original_path)\n",
    "    \n",
    "    # Generate each age progression\n",
    "    results = []\n",
    "    for i, (age_label, age_value) in enumerate(age_steps):\n",
    "        output_path = os.path.join(output_dir, f\"{age_label}_{age_value}.png\")\n",
    "        print(f\"Generating {age_label} ({age_value} years) version...\")\n",
    "        \n",
    "        # Age the face\n",
    "        aged_image = age_face(\n",
    "            image_path=image_path,\n",
    "            base_model_path=base_model_path,\n",
    "            target_age=age_label,\n",
    "            target_age_value=age_value,\n",
    "            strength=strength,\n",
    "            guidance_scale=guidance_scale,\n",
    "            output_path=output_path\n",
    "        )\n",
    "        \n",
    "        # Display in the subplot\n",
    "        axes[i+1].imshow(np.array(aged_image))\n",
    "        axes[i+1].set_title(f\"{age_label} ({age_value} years)\")\n",
    "        axes[i+1].axis(\"off\")\n",
    "        \n",
    "        results.append((age_label, age_value, output_path))\n",
    "    \n",
    "    # Save and display the composite image\n",
    "    plt.tight_layout()\n",
    "    composite_path = os.path.join(output_dir, \"age_progression.png\")\n",
    "    plt.savefig(composite_path)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nAge progression complete! Results saved to:\")\n",
    "    print(f\"Original: {original_path}\")\n",
    "    for age_label, age_value, path in results:\n",
    "        print(f\"{age_label} ({age_value} years): {path}\")\n",
    "    print(f\"Composite: {composite_path}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9c485c6-7360-4b9f-b23e-5d986c35a371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model runwayml/stable-diffusion-v1-5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd364ad817541dc91d4eaaa64fd98b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0b127b73384f7e82de4ada67c637f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5184eee072a4c2e91d627b20e15781c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29da404637e7438088505ef09f9d10f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download image: 404\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c82166970a58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://raw.githubusercontent.com/NVlabs/ffhq-dataset/master/thumbnails128x128/00000/00000.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m aged_face = age_face(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimage_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtarget_age\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"elderly\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtarget_age_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-10bcc9a16a4c>\u001b[0m in \u001b[0;36mage_face\u001b[0;34m(image_path, base_model_path, target_age, target_age_value, strength, num_inference_steps, guidance_scale, output_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Resize image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m768\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# Maintain aspect ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/NVlabs/ffhq-dataset/master/thumbnails128x128/00000/00000.png\"\n",
    "aged_face = age_face(\n",
    "    image_path=url,\n",
    "    target_age=\"elderly\",\n",
    "    target_age_value=75,\n",
    "    output_path=\"aged_face.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a675179-5c7c-4b4d-b284-500846f8a7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
